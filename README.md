# 社会化海量数据采集爬虫框架
参考了[这篇文章](http://www.lanceyan.com/tech/arch/snscrawler.html)

# 分布式方法
使用一个MQ服务, 提供User_ID查询功能, 用来各个分布式节点查询任务.
分布式节点采用multiprocessing的方法, 利用多线程技术来进行抓取, 将结果放到结果队列中, 单独起一个线程用来储存数据到数据库中.

# spider.py
主要负责爬虫的相关操作, 利用python自带的multiprocessing包进行多协程处理, 充分利用多核多线程. 但是python本身由于GIL的限制, 无法实现多核CPU利用.

# db.py
数据库类

* 查询user_id: 一次性查询200个数据, 避免空请求造成线程浪费.
* 插入数据: 传递query字符串和相对应的数据, 进行插入操作.

# message_queue.py
消息队列, 使用rq作为简单的消息队列. 现阶段主要负责结果数据的处理, 但是考虑将user_id队列加入其中.
如果加入任务队列的逻辑, 那么就需要自动抓取数据库的user_id, 理论类似EPR系统, 即每次进行任务处理之后, 就进行补充, 这样的好处是可以进行进度监控.
使用分布式系统的时候, 需要将mq系统与客户端进行网络通信. 
消息队列的主要作用是进行任务分配和结果处理. 而psycopg2包是不建议多线程共用一个connection的, 所以处理结果时, 可以放入队列中, 进行单线程写入. 主要占用IO.
而任务分配时, 客户端向MQ请求任务分配, 自动将任务分配给客户端相应的Index和Limit. 而客户端进行多线程爬取.